(pytorch) [kelo@kelo-hp firenet]$ python lighternet_pytorch_v2.py
Loading FireNet dataset with (64, 64) dimensions
Loading images...
Ok
x_train shape: (1696, 64, 64, 3)
1696 train samples -1.0 1.0
786 fire
910 no_fire
x_val shape: (729, 64, 64, 3)
729 test samples -1.0 1.0
338 fire
391 no_fire
num_classes 2 input_shape (64, 64, 3)
LighterNet(
  (firstBlock): Sequential(
    (0): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (firstOctave): Sequential(
    (0): OctConv2d(in_channels=(low: 0, high: 32), out_channels=(low: 16, high: 48),
              kernel_size=(3, 3), stride=(1, 1),
              padding=0, alphas=(0.0, 0.25), bias=False)
    (1): _BatchNorm2d(
      (bnh): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bnl): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): _SELU(inplace=True)
  )
  (avg_pool): _AvgPool2d(kernel_size=3, stride=2, padding=1)
  (middleOctave): Sequential(
    (0): OctConv2d(in_channels=(low: 16, high: 48), out_channels=(low: 8, high: 24),
              kernel_size=(3, 3), stride=(1, 1),
              padding=0, alphas=(0.25, 0.25), bias=False)
    (1): _BatchNorm2d(
      (bnh): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bnl): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): _SELU(inplace=True)
  )
  (avg_pool2): _AvgPool2d(kernel_size=3, stride=2, padding=1)
  (lastOctave): Sequential(
    (0): OctConv2d(in_channels=(low: 8, high: 24), out_channels=(low: 0, high: 64),
              kernel_size=(3, 3), stride=(1, 1),
              padding=1, alphas=(0.25, 0.0), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): SELU(inplace=True)
  )
  (classifier): Sequential(
    (0): Dropout(p=0.2, inplace=False)
    (1): Linear(in_features=64, out_features=2, bias=True)
  )
)
Epoch 001/100: Train Loss: 0.0180 Acc: 0.7152 | Val Loss: 0.0168 Acc: 0.7476 | time elapsed: 0m 9s
Epoch 002/100: Train Loss: 0.0157 Acc: 0.7647 | Val Loss: 0.0147 Acc: 0.7915 | time elapsed: 0m 9s
Epoch 003/100: Train Loss: 0.0144 Acc: 0.7919 | Val Loss: 0.0126 Acc: 0.8244 | time elapsed: 0m 9s
Epoch 004/100: Train Loss: 0.0132 Acc: 0.8007 | Val Loss: 0.0119 Acc: 0.8368 | time elapsed: 0m 9s
Epoch 005/100: Train Loss: 0.0122 Acc: 0.8154 | Val Loss: 0.0125 Acc: 0.8230 | time elapsed: 0m 9s
Epoch 006/100: Train Loss: 0.0117 Acc: 0.8243 | Val Loss: 0.0112 Acc: 0.8601 | time elapsed: 0m 9s
Epoch 007/100: Train Loss: 0.0113 Acc: 0.8396 | Val Loss: 0.0128 Acc: 0.8230 | time elapsed: 0m 9s
Epoch 008/100: Train Loss: 0.0102 Acc: 0.8514 | Val Loss: 0.0124 Acc: 0.8230 | time elapsed: 0m 9s
Epoch 009/100: Train Loss: 0.0103 Acc: 0.8626 | Val Loss: 0.0105 Acc: 0.8656 | time elapsed: 0m 9s
Epoch 010/100: Train Loss: 0.0102 Acc: 0.8526 | Val Loss: 0.0120 Acc: 0.8491 | time elapsed: 0m 9s
Epoch 011/100: Train Loss: 0.0096 Acc: 0.8750 | Val Loss: 0.0113 Acc: 0.8546 | time elapsed: 0m 9s
Epoch 012/100: Train Loss: 0.0099 Acc: 0.8573 | Val Loss: 0.0106 Acc: 0.8669 | time elapsed: 0m 9s
Epoch 013/100: Train Loss: 0.0093 Acc: 0.8809 | Val Loss: 0.0104 Acc: 0.8711 | time elapsed: 0m 9s
Epoch 014/100: Train Loss: 0.0088 Acc: 0.8833 | Val Loss: 0.0099 Acc: 0.8752 | time elapsed: 0m 9s
Epoch 015/100: Train Loss: 0.0080 Acc: 0.8962 | Val Loss: 0.0095 Acc: 0.8957 | time elapsed: 0m 9s
Epoch 016/100: Train Loss: 0.0079 Acc: 0.8962 | Val Loss: 0.0095 Acc: 0.8779 | time elapsed: 0m 9s
Epoch 017/100: Train Loss: 0.0080 Acc: 0.8962 | Val Loss: 0.0098 Acc: 0.8765 | time elapsed: 0m 9s
Epoch 018/100: Train Loss: 0.0078 Acc: 0.8927 | Val Loss: 0.0111 Acc: 0.8587 | time elapsed: 0m 9s
Epoch 019/100: Train Loss: 0.0084 Acc: 0.8874 | Val Loss: 0.0104 Acc: 0.8669 | time elapsed: 0m 9s
Epoch 020/100: Train Loss: 0.0081 Acc: 0.8909 | Val Loss: 0.0096 Acc: 0.8807 | time elapsed: 0m 9s
Epoch 021/100: Train Loss: 0.0072 Acc: 0.9045 | Val Loss: 0.0129 Acc: 0.8381 | time elapsed: 0m 9s
Epoch 022/100: Train Loss: 0.0074 Acc: 0.9015 | Val Loss: 0.0110 Acc: 0.8656 | time elapsed: 0m 9s
Epoch 023/100: Train Loss: 0.0068 Acc: 0.9186 | Val Loss: 0.0101 Acc: 0.8861 | time elapsed: 0m 9s
Epoch 024/100: Train Loss: 0.0071 Acc: 0.9062 | Val Loss: 0.0093 Acc: 0.8875 | time elapsed: 0m 10s
Epoch 025/100: Train Loss: 0.0067 Acc: 0.9157 | Val Loss: 0.0134 Acc: 0.8436 | time elapsed: 0m 9s
Epoch 026/100: Train Loss: 0.0067 Acc: 0.9104 | Val Loss: 0.0120 Acc: 0.8505 | time elapsed: 0m 9s
Epoch 027/100: Train Loss: 0.0065 Acc: 0.9169 | Val Loss: 0.0093 Acc: 0.8985 | time elapsed: 0m 9s
Epoch 028/100: Train Loss: 0.0061 Acc: 0.9287 | Val Loss: 0.0107 Acc: 0.8724 | time elapsed: 0m 9s
Epoch 029/100: Train Loss: 0.0062 Acc: 0.9157 | Val Loss: 0.0097 Acc: 0.8875 | time elapsed: 0m 9s
Epoch 030/100: Train Loss: 0.0073 Acc: 0.9045 | Val Loss: 0.0089 Acc: 0.8916 | time elapsed: 0m 9s
Epoch 031/100: Train Loss: 0.0068 Acc: 0.9121 | Val Loss: 0.0115 Acc: 0.8615 | time elapsed: 0m 9s
Epoch 032/100: Train Loss: 0.0060 Acc: 0.9222 | Val Loss: 0.0100 Acc: 0.8820 | time elapsed: 0m 9s
Epoch 033/100: Train Loss: 0.0070 Acc: 0.9110 | Val Loss: 0.0095 Acc: 0.8889 | time elapsed: 0m 9s
Epoch 034/100: Train Loss: 0.0063 Acc: 0.9157 | Val Loss: 0.0106 Acc: 0.8738 | time elapsed: 0m 9s
Epoch 035/100: Train Loss: 0.0056 Acc: 0.9269 | Val Loss: 0.0088 Acc: 0.9067 | time elapsed: 0m 9s
Epoch 036/100: Train Loss: 0.0057 Acc: 0.9257 | Val Loss: 0.0098 Acc: 0.8807 | time elapsed: 0m 9s
Epoch 037/100: Train Loss: 0.0062 Acc: 0.9180 | Val Loss: 0.0094 Acc: 0.8957 | time elapsed: 0m 9s
Epoch 038/100: Train Loss: 0.0055 Acc: 0.9304 | Val Loss: 0.0100 Acc: 0.8807 | time elapsed: 0m 9s
Epoch 039/100: Train Loss: 0.0056 Acc: 0.9328 | Val Loss: 0.0109 Acc: 0.8560 | time elapsed: 0m 9s
Epoch 040/100: Train Loss: 0.0054 Acc: 0.9316 | Val Loss: 0.0103 Acc: 0.8711 | time elapsed: 0m 9s
Epoch 041/100: Train Loss: 0.0054 Acc: 0.9298 | Val Loss: 0.0104 Acc: 0.8875 | time elapsed: 0m 9s
Epoch 042/100: Train Loss: 0.0051 Acc: 0.9346 | Val Loss: 0.0089 Acc: 0.8999 | time elapsed: 0m 9s
Epoch 043/100: Train Loss: 0.0062 Acc: 0.9233 | Val Loss: 0.0094 Acc: 0.8971 | time elapsed: 0m 9s
Epoch 044/100: Train Loss: 0.0054 Acc: 0.9328 | Val Loss: 0.0094 Acc: 0.8903 | time elapsed: 0m 9s
Epoch 045/100: Train Loss: 0.0050 Acc: 0.9387 | Val Loss: 0.0094 Acc: 0.9012 | time elapsed: 0m 9s
Epoch 046/100: Train Loss: 0.0053 Acc: 0.9440 | Val Loss: 0.0089 Acc: 0.8861 | time elapsed: 0m 9s
Epoch 047/100: Train Loss: 0.0047 Acc: 0.9446 | Val Loss: 0.0092 Acc: 0.8916 | time elapsed: 0m 9s
Epoch 048/100: Train Loss: 0.0052 Acc: 0.9381 | Val Loss: 0.0120 Acc: 0.8738 | time elapsed: 0m 9s
Epoch 049/100: Train Loss: 0.0045 Acc: 0.9399 | Val Loss: 0.0118 Acc: 0.8779 | time elapsed: 0m 9s
Epoch 050/100: Train Loss: 0.0052 Acc: 0.9292 | Val Loss: 0.0084 Acc: 0.9108 | time elapsed: 0m 9s
Epoch 051/100: Train Loss: 0.0045 Acc: 0.9458 | Val Loss: 0.0096 Acc: 0.9040 | time elapsed: 0m 9s
Epoch 052/100: Train Loss: 0.0049 Acc: 0.9393 | Val Loss: 0.0101 Acc: 0.9067 | time elapsed: 0m 9s
Epoch 053/100: Train Loss: 0.0041 Acc: 0.9540 | Val Loss: 0.0091 Acc: 0.8971 | time elapsed: 0m 9s
Epoch 054/100: Train Loss: 0.0045 Acc: 0.9404 | Val Loss: 0.0096 Acc: 0.8834 | time elapsed: 0m 9s
Epoch 055/100: Train Loss: 0.0043 Acc: 0.9469 | Val Loss: 0.0106 Acc: 0.8916 | time elapsed: 0m 9s
Epoch 056/100: Train Loss: 0.0046 Acc: 0.9422 | Val Loss: 0.0092 Acc: 0.9012 | time elapsed: 0m 9s
Epoch 057/100: Train Loss: 0.0038 Acc: 0.9581 | Val Loss: 0.0102 Acc: 0.8903 | time elapsed: 0m 9s
Epoch 058/100: Train Loss: 0.0044 Acc: 0.9458 | Val Loss: 0.0082 Acc: 0.9136 | time elapsed: 0m 9s
Epoch 059/100: Train Loss: 0.0037 Acc: 0.9534 | Val Loss: 0.0079 Acc: 0.9218 | time elapsed: 0m 9s
Epoch 060/100: Train Loss: 0.0036 Acc: 0.9558 | Val Loss: 0.0088 Acc: 0.9040 | time elapsed: 0m 9s
Epoch 061/100: Train Loss: 0.0038 Acc: 0.9528 | Val Loss: 0.0111 Acc: 0.8930 | time elapsed: 0m 9s
Epoch 062/100: Train Loss: 0.0040 Acc: 0.9505 | Val Loss: 0.0113 Acc: 0.8861 | time elapsed: 0m 9s
Epoch 063/100: Train Loss: 0.0048 Acc: 0.9422 | Val Loss: 0.0076 Acc: 0.9163 | time elapsed: 0m 9s
Epoch 064/100: Train Loss: 0.0039 Acc: 0.9517 | Val Loss: 0.0091 Acc: 0.9081 | time elapsed: 0m 9s
Epoch 065/100: Train Loss: 0.0039 Acc: 0.9522 | Val Loss: 0.0092 Acc: 0.9053 | time elapsed: 0m 9s
Epoch 066/100: Train Loss: 0.0036 Acc: 0.9534 | Val Loss: 0.0079 Acc: 0.9081 | time elapsed: 0m 9s
Epoch 067/100: Train Loss: 0.0034 Acc: 0.9599 | Val Loss: 0.0088 Acc: 0.9122 | time elapsed: 0m 9s
Epoch 068/100: Train Loss: 0.0039 Acc: 0.9534 | Val Loss: 0.0085 Acc: 0.9136 | time elapsed: 0m 9s
Epoch 069/100: Train Loss: 0.0034 Acc: 0.9605 | Val Loss: 0.0083 Acc: 0.9163 | time elapsed: 0m 9s
Epoch 070/100: Train Loss: 0.0037 Acc: 0.9570 | Val Loss: 0.0096 Acc: 0.9108 | time elapsed: 0m 9s
Epoch 071/100: Train Loss: 0.0036 Acc: 0.9552 | Val Loss: 0.0082 Acc: 0.9081 | time elapsed: 0m 9s
Epoch 072/100: Train Loss: 0.0032 Acc: 0.9605 | Val Loss: 0.0098 Acc: 0.8903 | time elapsed: 0m 9s
Epoch 073/100: Train Loss: 0.0038 Acc: 0.9481 | Val Loss: 0.0076 Acc: 0.9246 | time elapsed: 0m 9s
Epoch 074/100: Train Loss: 0.0034 Acc: 0.9623 | Val Loss: 0.0125 Acc: 0.8820 | time elapsed: 0m 9s
Epoch 075/100: Train Loss: 0.0040 Acc: 0.9499 | Val Loss: 0.0091 Acc: 0.9081 | time elapsed: 0m 9s
Epoch 076/100: Train Loss: 0.0033 Acc: 0.9623 | Val Loss: 0.0101 Acc: 0.8985 | time elapsed: 0m 9s
Epoch 077/100: Train Loss: 0.0029 Acc: 0.9735 | Val Loss: 0.0093 Acc: 0.8999 | time elapsed: 0m 9s
Epoch 078/100: Train Loss: 0.0035 Acc: 0.9605 | Val Loss: 0.0089 Acc: 0.9122 | time elapsed: 0m 9s
Epoch 079/100: Train Loss: 0.0039 Acc: 0.9446 | Val Loss: 0.0106 Acc: 0.8971 | time elapsed: 0m 9s
Epoch 080/100: Train Loss: 0.0029 Acc: 0.9617 | Val Loss: 0.0088 Acc: 0.9163 | time elapsed: 0m 9s
Epoch 081/100: Train Loss: 0.0028 Acc: 0.9682 | Val Loss: 0.0115 Acc: 0.8957 | time elapsed: 0m 9s
Epoch 082/100: Train Loss: 0.0031 Acc: 0.9605 | Val Loss: 0.0080 Acc: 0.9081 | time elapsed: 0m 9s
Epoch 083/100: Train Loss: 0.0028 Acc: 0.9658 | Val Loss: 0.0096 Acc: 0.9204 | time elapsed: 0m 9s
Epoch 084/100: Train Loss: 0.0033 Acc: 0.9581 | Val Loss: 0.0099 Acc: 0.8971 | time elapsed: 0m 9s
Epoch 085/100: Train Loss: 0.0038 Acc: 0.9534 | Val Loss: 0.0107 Acc: 0.8930 | time elapsed: 0m 9s
Epoch 086/100: Train Loss: 0.0027 Acc: 0.9652 | Val Loss: 0.0094 Acc: 0.9150 | time elapsed: 0m 9s
Epoch 087/100: Train Loss: 0.0033 Acc: 0.9587 | Val Loss: 0.0117 Acc: 0.9026 | time elapsed: 0m 9s
Epoch 088/100: Train Loss: 0.0039 Acc: 0.9505 | Val Loss: 0.0092 Acc: 0.9163 | time elapsed: 0m 9s
Epoch 089/100: Train Loss: 0.0032 Acc: 0.9676 | Val Loss: 0.0103 Acc: 0.9095 | time elapsed: 0m 9s
Epoch 090/100: Train Loss: 0.0028 Acc: 0.9682 | Val Loss: 0.0085 Acc: 0.9177 | time elapsed: 0m 9s
Epoch 091/100: Train Loss: 0.0028 Acc: 0.9658 | Val Loss: 0.0089 Acc: 0.9191 | time elapsed: 0m 9s
Epoch 092/100: Train Loss: 0.0026 Acc: 0.9676 | Val Loss: 0.0107 Acc: 0.9012 | time elapsed: 0m 9s
Epoch 093/100: Train Loss: 0.0029 Acc: 0.9629 | Val Loss: 0.0106 Acc: 0.9012 | time elapsed: 0m 9s
Epoch 094/100: Train Loss: 0.0037 Acc: 0.9522 | Val Loss: 0.0113 Acc: 0.8971 | time elapsed: 0m 9s
Epoch 095/100: Train Loss: 0.0028 Acc: 0.9634 | Val Loss: 0.0117 Acc: 0.8957 | time elapsed: 0m 9s
Epoch 096/100: Train Loss: 0.0033 Acc: 0.9575 | Val Loss: 0.0122 Acc: 0.8944 | time elapsed: 0m 9s
Epoch 097/100: Train Loss: 0.0022 Acc: 0.9788 | Val Loss: 0.0084 Acc: 0.9232 | time elapsed: 0m 9s
Epoch 098/100: Train Loss: 0.0028 Acc: 0.9682 | Val Loss: 0.0091 Acc: 0.9163 | time elapsed: 0m 9s
Epoch 099/100: Train Loss: 0.0022 Acc: 0.9758 | Val Loss: 0.0083 Acc: 0.9150 | time elapsed: 0m 9s
Epoch 100/100: Train Loss: 0.0023 Acc: 0.9729 | Val Loss: 0.0083 Acc: 0.9218 | time elapsed: 0m 9s
Training complete in 14m 34s
Best val Acc: 0.924554
Loading FireNet-Test dataset with (64, 64) dimensions
Loading images...
Ok
x_test shape: (871, 64, 64, 3)
871 test samples
593 fire
278 no_fire
num_classes 2 input_shape (64, 64, 3)
Evaluating model
Accuracy of the network on the test images: 95.41%
Classification Report
              precision    recall  f1-score   support

     No Fire       0.97      0.88      0.92       278
        Fire       0.95      0.99      0.97       593

    accuracy                           0.95       871
   macro avg       0.96      0.94      0.95       871
weighted avg       0.95      0.95      0.95       871


(pytorch) [kelo@kelo-hp firenet]$ python pytorch_profile.py 
Register FLOP counter for module Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1), bias=False)
THOP has not implemented counting method for  BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
Register FLOP counter for module ReLU6(inplace=True)
Register FLOP counter for module MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
Register FLOP counter for module AvgPool2d(kernel_size=(2, 2), stride=2, padding=0)
Register FLOP counter for module Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), bias=False)
Register FLOP counter for module Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)
THOP has not implemented counting method for  BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
THOP has not implemented counting method for  BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
THOP has not implemented counting method for  _SELU(inplace=True)
THOP has not implemented counting method for  _AvgPool2d(kernel_size=3, stride=2, padding=1)
Register FLOP counter for module AvgPool2d(kernel_size=(2, 2), stride=2, padding=0)
Register FLOP counter for module Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), bias=False)
Register FLOP counter for module Conv2d(48, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)
Register FLOP counter for module Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), bias=False)
Register FLOP counter for module Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)
THOP has not implemented counting method for  BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
THOP has not implemented counting method for  BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
THOP has not implemented counting method for  _SELU(inplace=True)
THOP has not implemented counting method for  _AvgPool2d(kernel_size=3, stride=2, padding=1)
Register FLOP counter for module AvgPool2d(kernel_size=(2, 2), stride=2, padding=0)
Register FLOP counter for module Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
Register FLOP counter for module Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
THOP has not implemented counting method for  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
THOP has not implemented counting method for  SELU(inplace=True)
Register FLOP counter for module Dropout(p=0.2, inplace=False)
Register FLOP counter for module Linear(in_features=64, out_features=2, bias=True)
LighterNet flops, params 27.773M 60.514K
